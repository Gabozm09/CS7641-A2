{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "import mlrose_hiive as mr\n",
    "import time \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch dataset \n",
    "bank_marketing = fetch_ucirepo(id=222) \n",
    "\n",
    "# data (as pandas dataframes) \n",
    "x_bank = bank_marketing.data.features.copy() \n",
    "y_bank = bank_marketing.data.targets.copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_data = pd.concat([x_bank, y_bank], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ['job','contact','poutcome']:\n",
    "    mode_value = bank_data[column].mode()[0]\n",
    "    bank_data.loc[:, column] = bank_data[column].fillna(mode_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_data = pd.get_dummies(bank_data, columns=['job', 'marital','education','month','poutcome'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "binary_columns = ['default','housing','loan','contact','y']\n",
    "label = LabelEncoder()\n",
    "for col in binary_columns:\n",
    "    bank_data[col] = label.fit_transform(bank_data[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bank = bank_data.drop('y', axis=1)\n",
    "y_bank = bank_data['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bank_train, X_bank_test, y_bank_train, y_bank_test = train_test_split(X_bank, y_bank, test_size=0.20, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_bank_train = scaler.fit_transform(X_bank_train)\n",
    "X_bank_test = scaler.transform(X_bank_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sampling = SMOTE(random_state=43)\n",
    "X_bank_train, y_bank_train = sampling.fit_resample(X_bank_train, y_bank_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New function for discretizing weights\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "def discretize_weights(weights, bins=10):\n",
    "    \"\"\"Discretize weights into a specified number of bins.\"\"\"\n",
    "    return np.digitize(weights, bins=np.linspace(weights.min(), weights.max(), bins))\n",
    "\n",
    "def compare_continuous_discrete(nn, X, y):\n",
    "    \"\"\"Compare performance of continuous and discretized weights.\"\"\"\n",
    "    continuous_pred = nn.predict(X)\n",
    "    continuous_accuracy = f1_score(y, continuous_pred)\n",
    "    \n",
    "    # Get the weights from the neural network\n",
    "    weights = nn.fitted_weights\n",
    "    \n",
    "    # Discretize the weights\n",
    "    discrete_weights = discretize_weights(weights)\n",
    "    \n",
    "    # Create a new neural network with discretized weights\n",
    "    discrete_nn = mr.NeuralNetwork(\n",
    "        hidden_nodes=nn.hidden_nodes,\n",
    "        activation=nn.activation,\n",
    "        algorithm=nn.algorithm,\n",
    "        max_iters=1,\n",
    "        bias=nn.bias,\n",
    "        is_classifier=nn.is_classifier,\n",
    "        learning_rate=nn.learning_rate,\n",
    "        early_stopping=nn.early_stopping,\n",
    "        clip_max=nn.clip_max,\n",
    "        max_attempts=nn.max_attempts,\n",
    "        random_state=nn.random_state\n",
    "    )\n",
    "    discrete_nn.fitted_weights = discrete_weights\n",
    "    \n",
    "    # Fit the discrete neural network to initialize internal structures\n",
    "    discrete_nn.fit(X, y)\n",
    "    \n",
    "    discrete_pred = discrete_nn.predict(X)\n",
    "    discrete_accuracy = f1_score(y, discrete_pred)\n",
    "    \n",
    "    return continuous_accuracy, discrete_accuracy\n",
    "\n",
    "def plot_weight_distribution(nn, algo_name):\n",
    "    weights = nn.fitted_weights\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(weights, bins=50, edgecolor='black')\n",
    "    plt.title(f'Weight Distribution for {algo_name}')\n",
    "    plt.xlabel('Weight Value')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "\n",
    "# Function to plot decision boundaries\n",
    "def plot_decision_boundary(nn, X, y, algo_name):\n",
    "    # Reduce to 2D using PCA\n",
    "    pca = PCA(n_components=2)\n",
    "    X_2d = pca.fit_transform(X)\n",
    "    \n",
    "    # Create a mesh grid\n",
    "    x_min, x_max = X_2d[:, 0].min() - 1, X_2d[:, 0].max() + 1\n",
    "    y_min, y_max = X_2d[:, 1].min() - 1, X_2d[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),\n",
    "                         np.arange(y_min, y_max, 0.1))\n",
    "    \n",
    "    # Predict for each point in the mesh\n",
    "    Z = nn.predict(pca.inverse_transform(np.c_[xx.ravel(), yy.ravel()]))\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    # Plot the decision boundary\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.contourf(xx, yy, Z, alpha=0.4)\n",
    "    plt.scatter(X_2d[:, 0], X_2d[:, 1], c=y, alpha=0.8)\n",
    "    plt.title(f'Decision Boundary for {algo_name}')\n",
    "    plt.xlabel('PCA Feature 1')\n",
    "    plt.ylabel('PCA Feature 2')\n",
    "    plt.show()\n",
    "\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "class NeuralNetworkWrapper(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.nn = mr.NeuralNetwork(**kwargs)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.nn.fit(X, y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.nn.predict(X)\n",
    "    \n",
    "# Function to plot learning curves\n",
    "def plot_learning_curves(X, y, algorithms):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    for i, algo in enumerate(algorithms):\n",
    "        nn_wrapper = NeuralNetworkWrapper(\n",
    "            hidden_nodes=[2], activation='relu', algorithm=algo, max_iters=1000,\n",
    "            bias=True, is_classifier=True, learning_rate=0.1, early_stopping=True, \n",
    "            clip_max=5, max_attempts=100, random_state=43\n",
    "        )\n",
    "        \n",
    "        train_sizes, train_scores, test_scores = learning_curve(\n",
    "            nn_wrapper, X, y, cv=5, n_jobs=-1, \n",
    "            train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "            scoring='f1'\n",
    "        )\n",
    "        \n",
    "        train_mean = np.mean(train_scores, axis=1)\n",
    "        train_std = np.std(train_scores, axis=1)\n",
    "        test_mean = np.mean(test_scores, axis=1)\n",
    "        test_std = np.std(test_scores, axis=1)\n",
    "        \n",
    "        plt.subplot(1, 3, i+1)\n",
    "        plt.plot(train_sizes, train_mean, 'o-', color='r', label='Training score')\n",
    "        plt.plot(train_sizes, test_mean, 'o-', color='g', label='Cross-validation score')\n",
    "        plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1, color='r')\n",
    "        plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, alpha=0.1, color='g')\n",
    "        plt.xlabel('Training examples')\n",
    "        plt.ylabel('F1 Score')\n",
    "        plt.title(f'Learning Curve for {algo}')\n",
    "        plt.legend(loc='best')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_functions = ['relu', 'sigmoid', 'tanh']\n",
    "algorithms = ['random_hill_climb', 'simulated_annealing', 'genetic_alg']\n",
    "\n",
    "neural_nets = {\n",
    "    f\"{algo}_{activ}\": mr.NeuralNetwork(\n",
    "        hidden_nodes=[2], activation=activ, algorithm=algo, max_iters=1000,\n",
    "        bias=True, is_classifier=True, learning_rate=0.1, early_stopping=True, \n",
    "        clip_max=5, max_attempts=100, random_state=43, curve=True\n",
    "    )\n",
    "    for algo in algorithms\n",
    "    for activ in activation_functions\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate each neural network\n",
    "results = {}\n",
    "for name, nn in neural_nets.items():\n",
    "    nn.fit(X_bank_train, y_bank_train)\n",
    "    y_test_pred = nn.predict(X_bank_test)\n",
    "    accuracy = f1_score(y_bank_test, y_test_pred)\n",
    "    results[name] = accuracy\n",
    "\n",
    "    # Compare continuous and discrete weights\n",
    "    cont_acc, disc_acc = compare_continuous_discrete(nn, X_bank_test, y_bank_test)\n",
    "    print(f\"{name} - Continuous accuracy: {cont_acc:.4f}, Discrete accuracy: {disc_acc:.4f}\")\n",
    "    \n",
    "    # Plot weight distribution\n",
    "    plot_weight_distribution(nn, name)\n",
    "    \n",
    "    # Plot decision boundary\n",
    "    plot_decision_boundary(nn, X_bank_test, y_bank_test, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to plot learning curves\n",
    "algorithms = ['random_hill_climb', 'simulated_annealing', 'genetic_alg']\n",
    "plot_learning_curves(X_bank_train, y_bank_train, algorithms)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
